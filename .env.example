## LLM provider selection
# Local dev (Ollama)
LLM_PROVIDER=ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b
OLLAMA_FORCE_GENERATE=false

## Hosted Qwen (OpenAI-compatible)
# LLM_PROVIDER=openai
# QWEN_API_BASE=https://YOUR_OPENAI_COMPAT_BASE/v1
# QWEN_API_KEY=your_api_key
# QWEN_MODEL=qwen2.5-14b-instruct

## Groq (OpenAI-compatible)
# LLM_PROVIDER=groq
# GROQ_API_BASE=https://api.groq.com/openai/v1
# GROQ_API_KEY=your_api_key
# GROQ_MODEL=llama-3.3-70b-versatile

## Reliability
LLM_MAX_RETRIES=2
LLM_RETRY_DELAY_MS=400
LLM_TIMEOUT_MS=30000

## Basic auth (optional)
# BASIC_AUTH_USER=
# BASIC_AUTH_PASS=
